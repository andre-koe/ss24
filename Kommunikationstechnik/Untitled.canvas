{
	"nodes":[
		{"id":"517eee614d5875ea","type":"text","text":"Übersicht verschiedener Kodierungsebenen\n\n- **Quellcodierung**\n- **Kanalcodierung**\n- **Leitungscodierung**","x":-2999,"y":-440,"width":759,"height":680},
		{"id":"1185978798e55c96","type":"text","text":"**Quellcodierung**\n\n**Ziel**: Maximieren der Information pro Bit\n\n**Strategie**: Eliminierung von redundanter Information\n\nBeispiele: MP3, MPEG, ZIP\n","x":-3060,"y":840,"width":280,"height":260},
		{"id":"b517bea2799e9a3f","type":"text","text":"Quellcodierung Grundidee\n\nZiel: \n- Repräsentation von Zeichen mit binären Codes, so dass die benötigte Anzahl Bits minimiert wird.\n\nGrundidee:\n- Verwendung unterschiedlich langer Codes\n\t- häufiges Zeichen: kurzer Code\n\t- seltenes Zeichen: langer Code\n\nBeispiel: Hochschule\n- H: 00\n- C: 01\n- O: 100\n- S: 101\n- U: 1100\n- L: 1101\n- E: 111\n\n=> 00 100 01 00 101 01 00 1100 1101 111 (27 Bits)\n-> Codierung ist optimal","x":-3305,"y":2200,"width":525,"height":634},
		{"id":"c6aaa8ae7df978a4","type":"text","text":"Codierung\n\nBinäre Codierung bedeutet, dass jedes Zeichen eines Wortes durch eine Bitsequenz repräsentiert wird.\n\nBinäre Codierung der Nachrichtenquelle \"HOCHSCHULE\":\n- 7 Zeichen -> 3 Bits\n\n\n| Zeichen | H   | C   | O   | S   | U   | L   | E   |\n| ------- | --- | --- | --- | --- | --- | --- | --- |\n| Code    | 000 | 001 | 010 | 011 | 100 | 101 | 110 |\nCodierung von \"HOCHSCHULE\": 000 010 001 000 011 001 000 100 101 110\n- 30 Bit\n\n=> Codierung ist nicht optimal, da HOCHSCHULE gemäß Informationsgehalt des Wortes theoretisch mit 27 Bit codiert werden kann\n","x":-2960,"y":1480,"width":669,"height":488},
		{"id":"82c4280abfb998d8","type":"text","text":"Entropiecodierung\n\nDie Entropiecodierung codiert einzelne Zeichen in einem Alphabet entsprechend einer bekannten oder geschätzten Auftrittswahrscheinlichkeit.\n\nDie verschiedenen Codierungsverfahren dienen dazu, eine Codierung der Zeichen zu ermitteln\n\n**Eine Codierung muss präfixfrei sein**, d.h. kein Codewort darf Präfix eines anderen Codeworts sein, da sonst keine eindeutige Dekodierung möglich ist.**","x":-3520,"y":3080,"width":500,"height":323},
		{"id":"0670f0aa4e319bfb","type":"text","text":"Codierung nach Shannon Fano","x":-4040,"y":3766,"width":306,"height":60},
		{"id":"7be4349a8925d6ea","type":"text","text":"Algorithmus\n\n\n1. Ordnen der Zeichen nach absteigender Auftrittswahrscheinlichkeit\n2. Aufteilen der Zeichen in zwei Hälften mit möglichst gleich großen Auftrittswahrscheinlichkeiten\n\t> Bei zwei gleich guten Möglichkeiten soll die                             Auftrittswahrscheinlichkeit der oberen Hälfte größer als die der unteren Hälfte sein \n3. An das Ende des Codeworts hinzufügen\n\t> einer \"0\" zu den Codewörtern der Zeichen der oberen Hälfte\n\t> einer \"1\" zu den Codewörtern der Zeichen der unteren Hälfte \n4. Wiederholen von 2. und 3. für die obere und untere Hälfte","x":-4680,"y":3991,"width":700,"height":389},
		{"id":"9a778a2d1fe79cc9","type":"text","text":"Beispiel: HOCHSCHULE\n\n| Zeichen   | H        | C        | O          | S          | U         | L         | E         |\n| --------- | -------- | -------- | ---------- | ---------- | --------- | --------- | --------- |\n| $p(x_i)$  | $3/10$   | $2/10$   | $1/10$     | $1/10$     | $1/10$    | $1/10$    | $1/10$    |\n| 1.Schritt | 0,5 / 0  | 0,5 / 0  | 0,5 / 1    | 0,5 / 1    | 0,5 / 1   | 0,5 / 1   | 0,5 / 1   |\n| 2.Schritt | 0,3 / 00 | 0,2 / 01 | 0,3 / 10   | 0,3 / 10   | 0,3 / 10  | 0,2 / 11  | 0,2 / 11  |\n| 3.Schritt | 00       | 01       | 0,2 / 100  | 0,2 / 100  | 0,1 / 101 | 0,1 / 110 | 0,1 / 111 |\n| 4.Schritt | 00       | 01       | 0,1 / 1000 | 0,1 / 1001 | 101       | 110       | 111       |\n| Codierung | 00       | 01       | 1000       | 1001       | 101       | 110       | 111       |\nEigenschaft: Präfixfreiheit","x":-5040,"y":4580,"width":760,"height":360},
		{"id":"d616a42efce61842","type":"text","text":"Algorithmus\n\n1. Ordne alle Zeichen nach aufsteigenden Auftrittswahrscheinlichkeiten in eine Liste\n2. Wiederhole bis nur noch ein zeichen in der Liste steht\n\t- füge dem Codewort des ersten Zeichens vorne eine \"1\" hinzu\n\t- füge dem Codewort des zweiten Zeichens vorne eine \"0\" hinzu\n\t- kombiniere die ersten beiden Zeichen zu einem Zeichen\n\t\t- bestimme die Summe der Auftrittswahrscheinlichkeiten\n\t\t- füge das kombinierte Zeichen entsprechend der berechneten Auftrittswahrscheinlichkeit in die Liste ein\n\t\t\t- falls in der Liste bereits Ueichen mit dieser Auftrittswahrscheinlichkeit vorkommen, wird das neue Zeichen nach diesen Zeichen eingefügt\n\t- lösche die beiden ersten Zeichen aus der Liste\n","x":-3767,"y":4600,"width":530,"height":575},
		{"id":"922843b66fd56be8","type":"text","text":"Codierung nach Huffman (auf Papier)\n\nListe 1: enthält alle Zeichen und deren Codierung\nListe 2: enthält alle Zeichen und kombinierten Zeichen mit deren Auftrittswahrscheinlichkeit\n\nAlgorithmus:\n1. Schreibe in Liste 1 alle Zeichen nach absteigenden Auftrittswahrscheinlichkeiten untereinander mit Platz links der Zeichen; hier wird später die Codierung der Zeichen notiert\n2. Schreibe in Liste 2 alle Zeichen mit niedrigster Auftrittswahrscheinlichkeit untereinander\n3. Kombiniere die beiden obersten noch nicht betrachteten Zeichen aus Liste 2\n\t- füge dem Codewort des obersten Zeichens vorne eine \"1\" hinzu (in Liste 1)\n\t- füge dem Codewort des unteren Zeichens vorne eine \"0\" hinzu (in Liste 1)\n\t- addiere die Auftrittswahrscheinlichkeiten der beiden Zeichen\n4. Füge unten in Liste 2 alle einzelnen Zeichen aus Liste 1 an, deren Auftrittswahrscheinlichkeit kleiner oder gleich der kombinierten Zeichens ist\n5. Füge unten in Liste 2 das kombinierte Zeichen an\n6. Wiederhole 3. bis nur noch ein nicht betrachtetes Zeichen vorkommt","x":-4237,"y":5349,"width":700,"height":566},
		{"id":"e93fa2b0576532f1","type":"text","text":"Beispiel: Siehe Notizbuch","x":-4313,"y":6059,"width":176,"height":56},
		{"id":"a24f39afd1d67f15","type":"text","text":"Codierung nach Huffman","x":-3620,"y":4380,"width":250,"height":60},
		{"id":"461a6eac8a2fb915","type":"text","text":"Arithmetische Codierung\n\nDie Arithmetische Codierung ist ein proprietäres Entropiecodierungsverfahren (IBM).\n\nWelches im Gegensatz zu den anderen beiden Verfahren Optimal Funktioniert, d.h. dass das theoretische Minimum der zur Codierung benötigten Bits erreicht wird.\n\n**Prinzip**:\n- Darstellung der gesamten Nachricht als zahl aus $[0, 1)$\n- Wiederholte aufteilung des Intervalls $[0,1)$ entsprechend der Auftrittswahrscheinlichkeiten der Zeichen","x":-2717,"y":5080,"width":437,"height":460},
		{"id":"e45852ae1a39ff1a","type":"text","text":"Wörterbuchcodierung\n\nNeben den bereits bekannten Verfahren der Entropiekodierung, bei denen eine Nachricht Zeichen für Zeichen derart codiert wird, dass überflüssige Redundanz reduziert wird. Existieren noch die Wörterbuchkodierungsverfahren, welche Redundanzen in Substrings erkennen und reduzieren.","x":-1120,"y":2400,"width":391,"height":326},
		{"id":"9babb74152ea293c","type":"text","text":"##### Lempel Ziv - Beispiel Codierung\n\n(Ohne Einschränkung für maximale Position und Länge)\n\n![[Pasted image 20240610140006.png]]","x":-2680,"y":3673,"width":509,"height":425},
		{"id":"24c1e58c731923aa","type":"text","text":"##### Lempel Ziv LZ77 \n\nCodierung von Strings in Tripel aus\n- Position: n Bit\n\t- 6 Bit bedeuten eine Referenzwörterbuchlänge von $2^6=64$ Zeichen\n- Anzahl: m Bit\n\t- 5 Bit bedeuten eine maximale Wortlänge von $2^5 = 32 Bit$\n- nächstem Zeichen (wie in der Originalnachricht)\n\t- benötigte Bits hängen von Anzahl Zeichen im Alphabet ab\n\nBeispiel:\n![[Pasted image 20240610141006.png]]\n\n- Insgesamt 32 Zeichen codiert in 15 Tripeln aus position (5 Bit), Anzahl (3 Bit), nächstem Zeichen (Annahme: 8 Bit bei ASCII-Code)\n\t- Codiert: 15 * (5 Bit + 3 Bit + 8 Bit)\n\t- Original: 32 * 8 Bit = 248 Bit\n- Effizient bei längeren Dateien mit Wörterbuchgröße von 2 bis 32 kBytes","x":-1600,"y":3673,"width":760,"height":607},
		{"id":"91f935ffae948f95","type":"text","text":"##### Lempel-Ziv-Welch (Verfahren)\n\nWörterbucheinträge bestehen aus Zeichenketten, denen Nummern zugewiesen werden\n\n- Initial besteht das Wörterbuch aus einem Grundalphabet, das hier nicht weiter betrachtet wird.\n- Im Beispiel wird von einem leeren ausgegangen\n\n**Codierung**:\n- Suche ab dem zu codierenden Zeichen die längste im Wörterbuch vorkommende Zeichenkette\n- hänge Nummer dieser Zeichenkette an das Codewort an\n- füge $<Nummer>$ + nächstes Zeichen dem Wörterbuch hinzu\n- fahre mit der Codierung ab dem nächsten Zeichen fort\n\n**Dekodierung**:\n- dekodierte Nachricht besteht aus Symbolen $y_i$, die einer Zeichenkette $x_{i,1},\\dots x_{i,K}$ entsprechen\n- bei Dekodierung von Symbol $y_{i+1}$\n\t- hänge Zeichenkette $x_{i,1},\\dots,x_{i,K}$\n\t- füge Zeichenkette $x_{i,1},\\dots,x_{i,K}y_{i+1,1}$ dem Wörterbuch hinzu","x":-767,"y":3660,"width":827,"height":535},
		{"id":"9e6b96c274244da5","type":"text","text":"##### Effiziente Implementierung mit variablen Bitlängen\n\n- Die Anzahl der Einträge in das Wörterbuch wächst bei Codierung und Decodierung gleichmäßig, so dass auch die Anzahl der Bits für die Wörterbuchindizes wachsen kann. Wenn wir also z.B. mit einem initialen Wörterbuch von 100 Einträgen starten, dann codieren wir die Wörterbuchindizes mit 7 Bits. Sobald das Wörterbuch 128 Einträge enthält, verwenden wir 8 Bits, ab 256 Einträgen 9 Bits und so weiter.","x":1040,"y":4640,"width":520,"height":300},
		{"id":"3fca96a18068d820","type":"text","text":"##### Naive Implementierung\n\nNachdem die Codierung abgeschlossen ist, kennen wir den größten Wörterbuch Eintrag und damit auch die Anzahl der zur Kodierung der Einträge benötigten Bits.","x":482,"y":4640,"width":370,"height":235},
		{"id":"bd21e699166a64cb","type":"text","text":"##### Lempel-Ziv-Welch - Binärdarstellung\n\nDas Ergebnis der bisherigen Codierung ist eine Folge Wörterbuchindizes, die noch binär codiert werden müssen.\n\n","x":667,"y":4320,"width":576,"height":164},
		{"id":"9e48d7010aa10a7f","type":"text","text":"##### Lempel-Ziv-Welch\n\nLempel-Ziv-Welch basiert auf dem dynamischen Aufbau eines Wörterbuchs beim Komprimieren\n\nBeispiel: **FISCHERSFRITZFISCHTFRISCHEFISCHE**\n\n![[Pasted image 20240610141809.png]]","x":-693,"y":2920,"width":680,"height":600},
		{"id":"28544e8342b6b896","type":"text","text":"**Leitungscodierung**\n\n**Ziel:** Darstellen von binärer Information in Form von Signalen die über den Kommunikationskanal übertragen werden können.","x":-8000,"y":-6240,"width":320,"height":199},
		{"id":"655e0ee01a6dace9","type":"text","text":"Historische Techniken\n\nHistorische Techniken im Bereich der Kommunikationstechnik umfassen sowohl optische, als auch akkustische wie auch elektrische bzw. später digitale Verfahren der Signalübertragung\n\nBekannte Vertreter sind bspw.\n- Trommeln, Rauchzeichen\n- Optische Telegrafen und Telegrafen\n- Morsecode\n- Funkwellen\n\n","x":3028,"y":-3520,"width":388,"height":390},
		{"id":"ec2ab7d1a3dc0aa6","type":"text","text":"# Kommunikationstechnik\n\nWas ist Kommunikationstechnik?\n\n*Kommunikationstechnik* umfasst Techniken zur **effizienten** und **fehlerfreien** Übertragung von Information von einer Quelle über einen gestörten (geteilten) Kommunikationskanal zu einer Senke","x":1680,"y":-2160,"width":440,"height":260},
		{"id":"b0be382a54b497ef","type":"text","text":"Kernfragen der Kommunikationstechnik","x":6414,"y":-2291,"width":250,"height":60},
		{"id":"c867bb4a06c04321","type":"text","text":"Wie lässt sich der Informationsgehalt einer Nachricht messen\n\n- Lassen sich Nachrichten beliebig verdichten?\n- Falls nein, wo befindet sich das theoretische Minimum?","x":6144,"y":-2140,"width":278,"height":290},
		{"id":"c4292759bb06d306","type":"text","text":"Wie lassen sich Nachrichten über rauschbehaftete (gestörte) Kanäle senden?\n\n- Lassen sich Nachrichten fehlerfrei übertragen?\n- Falls nein, wie weit lässt sich die Fehlerwahrscheinlichkeit senken","x":6614,"y":-2140,"width":350,"height":240},
		{"id":"f25fa473f6d287f6","type":"text","text":"Quellkodierungstheorem (Source Coding Theorem)\n\n- Informationsgehalt, Entropie\n- erlaubt Rückchlüsse auf die Grenzen der Datenkompression","x":6116,"y":-1700,"width":335,"height":220},
		{"id":"2c6d798e3800b221","type":"text","text":"Kanalkodierungstheorem (noisy channel theorem)\n\n- Kanalkapazität","x":6659,"y":-1700,"width":261,"height":160},
		{"id":"18cc36d3e791ad71","type":"file","file":"Pasted image 20240601191655.png","x":-1464,"y":118,"width":789,"height":562},
		{"id":"5b87ed4daedd3e8a","type":"text","text":"##### Entropieflüsse\n\n![[Pasted image 20240610161518.png]]\n\nDefinitionen:\n- Transinformationsgehalt:\n\t- $T(X,Y) = H(X)-H(X|Y)=H(Y)-H(Y|X)=H(X)+H(Y)-H(X,Y)$\n- Rückschlussentropie:\n\t- $H(X|Y) = \\sum_{j=1}^N p(y_j)\\sum_{i=1}^Np(x_i|y_i)\\cdot ld\\frac{1}{p(x_i|y_i)}$","x":5344,"y":1244,"width":800,"height":679},
		{"id":"df1021d3d6068acf","type":"text","text":"##### Kanalkapazität","x":6704,"y":1281,"width":250,"height":60},
		{"id":"109fa7b068eccc95","type":"text","text":"##### Beispiel\n\n**Quelle:**\n- Zeichen \"0\" und \"1\" mit gleichen Auftrittswahrscheinlichkeiten \n- Entropie der Quelle: 1 Bit\n\n**Übertragungskanal**\n- Verfälschung mit einer Wahrscheinlichkeit von $10\\%$ \n\t- Wahrscheinlichkeit für korrekte Übertragung: $90\\%$\n\t- Wahrscheinlichkeit füt Übertragungsfehler: $10\\%$\n\n**Senke**\n- Zeichen \"0\" und \"1\" treten auch hier mit Wahrscheinlichkeiten von $50\\%$ auf\n- Entropie der Senke: 1 Bit\n\nWie viel Information wird übertragen? Antwort gibt der **Transinformationsgehalt**","x":3544,"y":1203,"width":731,"height":498},
		{"id":"c6b988128e934ddb","type":"text","text":"##### Transinformationsgehalt\n\nBetrachtet ein Verbundereignis bestehend aus gesendetem und empfangenen Zeichen\n\n- Übertragungsfehler: \"0\" wird gesendet und \"1\" wird empfangen\n\t- Wahrscheinlichkeit für Verbundereignis: $p(x0, y1) = 0.5\\cdot 0.1 = 0.05$\n- Korrekte Übertragung: \"0\" wird gesendet und \"0\" wird empfangen\n\t- Wahrscheinlichkeit für Verbundereignis: $p(x0, y0) = 0.5\\cdot 0.9 = 0.045$\n\n**Transinformationsgehalt einer Übertragung:**\n- Gehalt der Information, die aus den empfangenen Zeichen an der Senke über die gesendeten Zeichen an der Quelle geschlossen werden kann\n\t- $I_T(x_i, y_i) = ld\\frac{p(x_i,y_i)}{p(x_i)\\cdot p(y_i)}$\n- Transinformationshehalt für Übertragungsfehler\n\t- $I_T(0,1) = ld\\frac{0.05}{0.5\\cdot 0.5} \\approx -2.322$\n- Transinformationshehalt für korrekte Übertragung\n\t- $I_T(0,0) = ld\\frac{0.45}{0.5\\cdot 0.5}\\approx 0.848$ ","x":4448,"y":1244,"width":781,"height":491},
		{"id":"c7be6527006c134d","type":"text","text":"##### Transinformationsgehalt eines Übertragungskanals\n\nTransinformationsgehalt eines Übertragungskanals\n- Erwartungswert des Transinformationsgehalts einer zufälligen Übertragung\n$$T(X,Y) = \\sum_{i=1}^N\\sum_{j=1}^Np(x_i, y_i)\\cdot ld\\frac{p(x_i, y_i)}{p(x_i)\\cdot p(y_j)}$$\nBeispiel:\n$$\\begin{align}T(X,Y) &= 0.05\\cdot I_T(0,1)+0.45\\cdot I_T(0,0) + 0.05\\cdot I_T(1,0) + 0.45\\cdot I_T(1,1) \\\\&= 0.1\\cdot -2.322\\cdot+0,9\\cdot 0.848 = 0.531\\end{align}$$\nUngestörter Kanal:\n$p(x_i,y_j) = \\begin{cases}p(x_i),&\\textrm{für}\\ i= j\\\\0,\\quad &\\textrm{sonst}\\end{cases}$\n\n$$I_T(1,1) = ld\\frac{p(x_i)}{p(x_i)\\cdot p(y_i)} = ld\\frac{1}{p(y_j)} = I(y_j)$$\n$$T(X,Y) = H(X) = H(Y)$$\nMaximal gestörter Kanal: $p(x_i, y_i) = p(x_i)\\cdot p(y_j)$\n$I_T(x_i,y_j) = ld\\ 1 = 0$\n$T(X,Y) = 0$\n\n\n\n","x":4496,"y":1883,"width":684,"height":620},
		{"id":"87bc56ce0e55adbf","type":"text","text":"Theoretische Grundlagen","x":4259,"y":164,"width":250,"height":60},
		{"id":"387ef32e9ba1d5f4","type":"text","text":"**Definition von Information**\n\nWir definieren:\n$$N(T) = \\textrm{Anzahl der Signale der Länge T}$$\nIst $N(T) = 2^n$, dann können $n$ Bits übertragen werden und damit überträgt der Kanal $\\frac{log_2N(T)}{T}$ Informationsbits pro Zeiteinheit\n\nDefinition der Kapazität $C$ eines diskreten Kanals von Claude Shannon:\n$$C=\\lim_{T\\rightarrow\\infty}\\frac{\\log_{2}N(T)}{T}$$\n","x":-6860,"y":1200,"width":580,"height":380},
		{"id":"8d54f64ec4068865","type":"text","text":"Beispiel: Entropie\n\nNachrichtenquelle sendet die Zeichen des Wortes \"HOCHSCHULE\" mit entsprechenden Auftrittswahrscheinlichkeiten\n\n\n| Zeichen  | H    | C    | O    | S    | U    | L    | E    |\n| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n| $p(x_i)$ | 3/10 | 2/10 | 1/10 | 1/10 | 1/10 | 1/10 | 1/10 |\n\nEntropie der Nachrichtenquelle:\n$$H(X) = 0,3\\cdot ld\\left(\\frac{10}{3}\\right) + 0,2\\cdot ld\\left(\\frac{10}{2}\\right)+5\\cdot 0,1\\cdot ld\\left(\\frac{10}{1}\\right) \\approx 2,646$$\n\n| Zeichen  | H     | C     | O     | S     | U     | L     | E     |\n| -------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |\n| $p(x_i)$ | 3/10  | 2/10  | 1/10  | 1/10  | 1/10  | 1/10  | 1/10  |\n| $I(x_i)$ | 1,737 | 2,322 | 3,322 | 3,322 | 3,322 | 3,322 | 3,322 |\n","x":-6950,"y":2780,"width":609,"height":422},
		{"id":"d0258f3739317a67","type":"text","text":"Entropie\n\nDefinition für $I_i$ (Informationsgehalt eines Zeichens)\n$$I_i=-ld(p(x_i))=ld\\frac{1}{p(x_i)}$$\nDefinition des mittleren Informationsgehalt einer Nachrichtenquelle\n$$H(X)=E[I(X)]=\\sum_{i=1}^Np(x_i)\\cdot I(x_i)=\\sum_{i=1}^Np(x_i)\\cdot ld\\frac{1}{p(x_i)}$$\n- $H(X)$ bezeichnet **Entropie** einer Nachrichtenquelle\n\t- eines Zeichenvorrats X mit Auftrittswahrscheinlichkeiten $p(x_i)$\n- $E[X]$ bezeichnet den Erwartungswert einer Zufallsvariablen $X$\n\t- die Entropie ist der mittlere Informationsgehalt eines zufälligen Zeichens, das die Nachrichtenquelle sendet","x":-6930,"y":2106,"width":570,"height":454},
		{"id":"c05473a10d540506","type":"text","text":"Beispiel: Mittlere Codewortlänge und Redundanz\n\n| Zeichen  | H    | C    | O    | S    | U    | L    | E    |\n| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n| $p(x_i)$ | 3/10 | 2/10 | 1/10 | 1/10 | 1/10 | 1/10 | 1/10 |\n| 1.Code   | 000  | 001  | 010  | 011  | 100  | 101  | 110  |\n| 2.Code   | 00   | 01   | 110  | 111  | 1000 | 1001 | 101  |\nWelcher Code ist besser?\n- Mittlere Codewortlänge:\n\t- Code 1: \n\t\t  $L_{C1} = 3$\n\t\t  $R_C = 3 -2,646 = 0,354$\n\t- Code 2:\n\t\t  $L_{C2} = (0,3 + 0,2)\\cdot 2 + 3 \\cdot 0,1 \\cdot 3 + 2\\cdot 0,1 \\cdot 4 = 2,7$\n\t\t  $R_C = 2,7 - 2,646 = 0,054$\n\n=> Durch geeignete Codierung kann die mittlere Codewortlänge  reduziert werden","x":-5932,"y":1930,"width":692,"height":540},
		{"id":"dab87958ebe7c43d","type":"text","text":"Theoretische Grundlagen der Quellcodierung","x":-5882,"y":1000,"width":410,"height":60},
		{"id":"5157e77767360ae9","type":"text","text":"Quellcodierung: Mittlere Codewortlänge und Redundanz\n\n**Mittlere Codewortlänge** einer Nachricht des Zeichenvorrats X\n\n$$L_C(X) = \\sum_{i=1}^Np(x_i)\\cdot l_c(x_i)$$\n- $l_c(x_i)$: Länge des binären Codeworts von $x_i$ bei Codierung mittels Code $C$\n- $p(x_i)$: Auftrittswahrscheinlichkeit von $x_i$\n\nInformationsgehalt entspricht Codewortlänge bei optimaler Codierung\n\n**Redundanz** einer Codierung: Differenz zwischen mittlerer Codewortlänge und mittlerem Informationsgehalt\n$$R_C(X) = L_C(X)-H(X)$$","x":-5882,"y":1302,"width":592,"height":438},
		{"id":"191f24319233ac48","type":"text","text":"**Informationsgehalt eines Zeichens**\n- hängt von der Auftrittswahrscheinlichkeit $p(x_i)$ ab\n$$I(x_i)=ld\\frac{1}{p(x_i)}$$\n\n**Informationsgehalt einer Nachricht $\\overline{x}$**\n- Summe der Informationsgehalte der Zeichen\n$$I(\\overline{x}) = \\sum_{i=0}^NI(x_i)$$\n\n**Entropie einer Nachrichtenquelle mit Zeichenvorrat $X$**\n- mittlerer Informationsgehalt eines Zeichens\n$$H_(X)=\\sum_{i=1}^Np(x_i)\\cdot ld\\frac{1}{p(x_i)}$$\n\n**Mittlere Codewortlänge eines Zeichenvorrats $X$ mit Codierung $C$**\n$$L_C(X)=\\sum_{i=0}^Np(x_i)\\cdot l_c(x_i)$$\n**Redundanz einer Codierung**\n- Differenz zwischen Entropie und mittlerer Codewortlänge\n\n$$R_C(X) = L_C(X)-H(X)$$","x":-6258,"y":60,"width":728,"height":740},
		{"id":"f23ed7c18bec1461","type":"text","text":"##### Beispiel DEFLATE\n\nDer Deflate wurde 1989 für das ZIP-Format entwickelt\n- außerdem genutzt z.B. für PNG, TIFF, PDF und HTTP Datenübertragung\n\nDEFLATE nutzt eine Kombination von Lempel-Ziv und Huffman-Kodierung\n- zunächst wird Lempel-Ziv durchgeführt und dann Huffman\n\nIn der Lempel-Ziv-Codierung werden die (0,0,C) Tripel durch das Literal C ersetzt\n\nDie Huffman-Codierung besteht dann aus zwei Teilen\n1. Ein Baum codiert die Literale und die Länge der Strings\n2. Ein Baum codiert die Distanzen (die Länge der Rückwärtsreferenz)\n\nHuffman-Bäume\n- es existieren vordefinierte Huffman-Bäume\n- es können spezielle Huffman-Bäume erzeugt und im Code gespeichert werden\n- der Code besteht aus Blöcken in denen unterschiedliche Huffman-Bäume verwendet werden können\n","x":-2240,"y":663,"width":680,"height":614},
		{"id":"49431eb38d5e6038","type":"text","text":"**Kanalcodierung**\n\n**Ziel**: Fehlerfreie Übertragung von Information über einen fehlerbehafteten Kommunikationskanal\n\n**Strategie**: Hinzufügung von nützlicher Redundanz\n\nBeispiele: CRC, Blockcode, Faltungscodes\n\nWobei die letzten beiden Typen nicht nur in der Lage sind Fehler zu erkennen, sondern diese Teilweise zu beheben.","x":671,"y":-6535,"width":449,"height":335},
		{"id":"582025b522476e90","type":"text","text":"##### Definitionen","x":2357,"y":-7951,"width":250,"height":60},
		{"id":"4adb979a2a7a24b6","type":"text","text":"![[Pasted image 20240609170633.png]]","x":-1746,"y":6722,"width":526,"height":355},
		{"id":"d33ab9e937aa02af","type":"text","text":"![[Pasted image 20240609170857.png]]","x":-1746,"y":7137,"width":526,"height":340},
		{"id":"09694231c3d110d4","type":"text","text":"![[Pasted image 20240609170600.png]]","x":-2916,"y":6720,"width":491,"height":357},
		{"id":"f74f5c79863a16b7","type":"text","text":"![[Pasted image 20240609170745.png]]","x":-2916,"y":7137,"width":491,"height":340},
		{"id":"0986f2c574e655a9","type":"text","text":"Codierungsvorschrift\n\n- Ordne Zeichen in beliebiger aber fester Reihenfolge an\n- Definiere für jedes zeichen $X_i$:\n\t- $p_i$: Auftrittswahrscheinlichkeit\n\t- $o_i = \\sum_{j=1}^{i-1}p_j$: Summe der Auftrittswahrscheinlichkeiten aller Zeichen mit kleinerem Index\n- Codierung einer Nachricht:\n\t- Variablen: $s$ für Start des Intervalls und $d$ für Breite des Intervalls der Nachricht\n\t- Initialisierung: $s = 0, d = 1$\n\t- Codierung eines Zeichens $X_i$:\n\t\t- $s = s+o_i\\cdot d$\n\t\t- $d = d\\cdot p_i$\n- Dekodierung einer Nachricht $y$ mit $k$ Zeichen:\n\t- für jedes der $k$ Zeichen:\n\t\t- bestimme das Zeichen $x_i$, für das gilt $y\\in[o_i, o_{i+1}]$\n\t\t- $y = (y-o_i)/p_i$\n","x":-3887,"y":6720,"width":677,"height":521},
		{"id":"c1075c4701be70cc","type":"text","text":"##### Lempel-Ziv\n\nBasiert auf der verwendung zuvor gelesener Daten als Wörterbuch.\n\nEinsatzgebiete:\n- In Kombination mit Huffman-Codierung als DEFLATE Algorithmus in ZIP, PNG, PDF\n\nVorgehen:\n- Zeichenkette wird über Tripel aus Position, Länge und nächstem Zeichen codiert.\n\t- Codiert wird längste Zeichenkette, die im bisherigen Text vorkam\n\t- Position wird ab der Stelle des codierten Zeichens rückwärts gezählt\n\t- Maximalwert für die Position beschränkt die Größe des Wörterbuchs\n\nBeispiel:\n![[Pasted image 20240610135557.png]]","x":-2171,"y":2840,"width":786,"height":600},
		{"id":"89847a999a816d4c","type":"text","text":"##### Beispiel Decodierung\n\n![[Pasted image 20240610140103.png]]","x":-2080,"y":3818,"width":368,"height":280},
		{"id":"696c04cd48ff6772","type":"text","text":"##### Beispiel Decodierung\n\n![[Pasted image 20240610143548.png]]","x":-903,"y":4400,"width":414,"height":379},
		{"id":"69f3df32340d3b48","type":"text","text":"##### Spezialfall\n\n**Nachricht**: \"XXXXXX\"\n\n**Codierung**:\n\n| Zeichen | Codierung | Wörterbuch |\n| :-----: | :-------: | :--------: |\n|    X    |     X     |    0:XX    |\n|   XX    |     0     |   1:XXX    |\n|   XXX   |     1     |            |\n\n**Decodierung**: X<0><1>\n\n| Nachricht | Ausgabe | Wörterbuch |\n| :-------: | :-----: | :--------: |\n|     X     |    X    |            |\n|    <0>    |    ?    |            |\n\n\n**Lösung für Decodierung**:\n- Wenn Eintrag nicht in Wörterbuch\n- Ausgabe: vorherige Ausgabe + erstes Zeichen von vorheriger Ausgabe\n\n**Decodierung**: X<0><1>\n\n| Nachricht | Ausgabe | Wörterbuch |\n| :-------: | :-----: | :--------: |\n|     X     |    X    |            |\n|    <0>    |   XX    |    0:XX    |\n|    <1>    |   XXX   |   1:XXX    |\n\n","x":-1039,"y":4920,"width":687,"height":729},
		{"id":"514a7c9fbf20c10b","type":"text","text":"##### Beispiel: Spezialfall\n\n**Nachricht:** BANANNANANNANNE\n\n| Zeichen | Codierung | Wörterbuch |\n| ------- | --------- | ---------- |\n| B       | B         | 0:BA       |\n| A       | A         | 1:AN       |\n| N       | N         | 2:NA       |\n| <1>     | AN        | 3:ANN      |\n| <2>     | NA        | 4:NAN      |\n| <4>     | NAN       | 5:NANN     |\n| <5>     | NANN      | 6:NANNE    |\n| E       | E         |            |\n\n**Decodierung**: BAN<1><2><4>E\n\n| Nachricht | Ausgabe | Wörterbuch |\n| :-------: | :-----: | :--------: |\n|     B     |    B    |            |\n|     A     |    A    |    0:BA    |\n|     N     |    N    |    1:AN    |\n|    <1>    |   AN    |    2:NA    |\n|    <2>    |   NA    |    3ANN    |\n|    <4>    |   NAN   |   4:NAN    |\n|    <5>    |  NANN   |   5:NANN   |\n|     E     |    E    |  6:NANNE   |\n","x":-1055,"y":5880,"width":360,"height":740},
		{"id":"af5d700dc26f73e3","type":"text","text":"##### Initiales Wörterbuch\n\nDas Ergebnis der bisherigen Codierung ist eine Folge von Zeichen und Wörterbuchindizes\n\nEine Implementierung würde mit den vorkommenden Zeichen als initialem Wörterbuch starten oder alternativ ein festes initiales Wörterbuch wie z.B. alle ASCII Zeichen verwenden.\n\nWenn in der Nachricht 100 Zeichen vorkommen, dann nehmen, diese die Wörterbucheinträge 0-99 ein und der bisherige Wörterbucheintrag 0 wird Wörterbucheintrag 100.\n\nDas initiale Wörterbuch muss dem Dekodierer bekannt sein.","x":-210,"y":4680,"width":540,"height":379},
		{"id":"cc6b58ebc825fd01","type":"text","text":"Maximaler Informationsgehalt\n\nDer Informationsgehalt ist maximal, wenn alle Zeichen die gleiche Auftrittswahrscheinlichkeit haben.\n\nBeispiel: binärer Kanal mit \"0\" und \"1\"\n- Auftrittswahrscheinlichkeit für \"0\": p\n- Auftrittswahrscheinlichkeit für: \"1\": 1-p\n\n- Informationsgehalt: $H(X) = p \\cdot ld\\left(\\frac{1}{p}\\right)+(1-p)\\cdot ld\\left(\\frac{1}{1-p}\\right)$\n\n![[Pasted image 20240601220545.png]]","x":-8520,"y":2680,"width":549,"height":572},
		{"id":"fb386bc90ec305ed","type":"text","text":"Informationsgehalt\n- Nachrichtenquelle:\n\t- Alphabet $X$ mit $N$ Zeichen $x_1, x_2, \\dots, x_N$\n\t- $p(x_i)$: Auftrittswahrscheinlichkeit für Zeichen $x_i$\n- gesucht: Maßzahl $I_i = f(p(x_i))$: Informationsgehalt eines Zeichens $x_i$\n\nDefinition für $I_i$\n\n$$I_i = -ld(p(x_i))=ld\\frac{1}{p(x_i)}$$","x":-8080,"y":2000,"width":460,"height":383},
		{"id":"a202e3332e1355e7","type":"text","text":"**Beispiel**: Informationsgehalt eines Wortes (\"HOCHSCHULE\")\n\n| Zeichen  | H       | C       | O       | S       | U       | L       | E       |\n| -------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- |\n| $p(x_i)$ | $3/10$  | $2/10$  | $1/10$  | $1/10$  | $1/10$  | $1/10$  | $1/10$  |\n| $I(x_i)$ | $1,737$ | $2,322$ | $3,322$ | $3,322$ | $3,322$ | $3,322$ | $3,322$ |\nInformationsgehalt:\n$$I_{ges}=3\\cdot 1.737+2\\cdot 2,322+5\\cdot 3,322 = 26,464$$\nDas Wort HOCHSCHULE kann theoretisch mit 27 Bit kodiert werden.","x":-7800,"y":2680,"width":721,"height":320},
		{"id":"5341d9fe72c6a75d","type":"text","text":"Fazit:\n- 8 Möglichkeiten auf 4 Möglichkeiten entspricht einer Information von 1 Bit\n- 8 Möglichkeiten auf 2 Möglichkeiten entspricht einer information von 2 Bit\n- 8 Möglichkeiten auf 1 Möglichkeit entspricht einer Information von 3 Bit\n\nAllgemein:\n- $2^n$ Möglichkeiten auf $2^m$ Möglichkeiten einzuschränken entspricht einer Information von $n-m$ Bit\n- $n$ Möglichkeiten auf $m$ Möglichkeiten einzuschränken entspricht einer Information von $ld\\ n - ld\\ m$ Bits\n\nEine Einschränkung von $n$ Möglichkeiten auf $m$ Möglichkeiten entspricht einer Information von\n$$ld\\frac{n}{m}\\quad\\textrm{Bits}$$","x":-7950,"y":1120,"width":660,"height":443},
		{"id":"d79691f8a494603b","type":"text","text":"Shannon'sche Kommunikationsmodell\n\n\n![[Pasted image 20240601190944.png]]\n\nDas Shannon'sche Kommunikationsmodell bildet die theoretische Grundlage der heutigen Kommunikation und führt das ***Bit*** als Einheit für Information ein.\n\nDamit wird der Informationsbegriff mathematisch erfassbar und ist nicht mehr an ein bestimmtes Übertragungsmedium gebunden.\n\n=> Erkenntnisse sind von nun an universeller Natur","x":1280,"y":480,"width":840,"height":1220},
		{"id":"0d51b125fbd11ac3","type":"text","text":"Was ist Information?\n\n*\"Eine Aussage oder Beobachtung ist dann informativ, wenn sie uns etwas mitteilt, das uns vorher nicht bekannt war. Nur über solche Dinge können wir jedenfalls Information gewinnen, über die uns bei uns ein gewisses Maß an Nichtwissen oder Ungewissheit besteht. In der Tat lässt sich **Infomation** als dasjenige erklären, das Ungewissheit beseitigt oder reduziert\"*","x":3600,"y":520,"width":409,"height":309},
		{"id":"62f00fe980f0d263","type":"text","text":"##### Informationsgehalt eines Übertragungskanals\n\n![[Pasted image 20240610154041.png]]\n","x":5280,"y":-320,"width":594,"height":627},
		{"id":"d824c8a29643ea95","type":"text","text":"##### Kapazität des binären Übertragungskanals\n\n![[Pasted image 20240610162918.png]]\n\nTransformationsgehalt des binären Übertragungskanals\n$$T(X,Y) = 1-(1,q)\\cdot ld\\frac{1}{1-q}-q\\cdot ld\\frac{1}{q}$$\nKapazität des binären Übertragungskanals\n$$C*=C\\cdot \\left\\{1-(1-q)\\cdot ld\\frac{1}{1-q}-q\\cdot ld\\frac{1}{q}\\right\\}$$\n","x":6840,"y":2563,"width":508,"height":467},
		{"id":"f9419bb037fef6a4","type":"file","file":"Pasted image 20240610163331.png","x":6894,"y":3103,"width":399,"height":263},
		{"id":"5a50e863528f68bb","type":"text","text":"##### Binärer Symmetrischer Übertragungskanal\n\n**BSC** Binary Symmetric Channel\n\nEigenschaften:\n- Binär\n\t- Übertragene Zeichen sind Bits\n- Symmetrisch:\n\t- Bitfehler mit Wahrscheinlichkeit q\n\t\t- Verfälschung von \"0\" nach \"1\" und \"1\" nach \"0\" sind gleich Wahrscheinlich\n\t- Maximale Entropie der Quelle:\n\t\t- Zeichen \"1\" und \"0\" sind gleichwahrscheinlich\n\nKanalkapazität: $C[bits/s]$ \n- Dauer eines Bits: 1/C\n\nWas ist die Kapazität des Kanals? Wie viel Information kann übertragen werden?","x":6480,"y":1720,"width":524,"height":541},
		{"id":"80955497da95af40","type":"text","text":"##### Shannon Kapazität\n\nDer zuvor beschriebene BSC stellt ein Modell dar, in dem die tatsächliche Störung von Signalen auf Bitfehlerwahrscheinlichkeiten abbgebildet wird.\n\nIn der Realität haben wir einen kontinuierlichen analogen Übertragungskanal, auf dem analoge Signale übertragen und gstört werden\n\n- Bandbreite des Kanals: $B[MHz]$\n\t- z.B. WLAN Kanal mit 20Mhz\n- Signal-Rausch-Verhältnis (SNR, Signal-to-Noise-Ratio):\n  Verhältnis von Leistung des Sendesignals $P_S$ zu Rauschleistung $P_N$ am Empfänger\n- Shannon-Kapazität des Kanals\n  $$C*=B\\cdot \\log_2(1+SNR)$$","x":7480,"y":1720,"width":580,"height":487},
		{"id":"5606db9c9cd3a7bf","type":"text","text":"Beispiel: HSDPA\n\nModerne Übertragungsverfahren erreichen fast die theroretische Shannon-Kapazität - mit MIMO wurde das Shannon-Limit durchbrochen\n\n![[Pasted image 20240610164703.png]]","x":7840,"y":2400,"width":580,"height":473},
		{"id":"5e929a9d4cabeb22","type":"file","file":"Pasted image 20240618065830.png","x":55,"y":-5362,"width":420,"height":50},
		{"id":"7137db165e777e21","type":"text","text":"##### Prinzip der Kanalcodierung","x":680,"y":-5880,"width":380,"height":61},
		{"id":"c75c40e1ccb1d4b3","type":"text","text":"##### Beispiel IBAN\n\nIBAN: DE 32 69050001 0123456789\nAufbau:\n- Ländercode (CC, 2 Zeichen)\n- Prüfziffer (CS, 2 Zeichen)\n- Bankleitzahl (BLZ, 8 Zeichen)\n- Kontonummer (KTN, 10 Zeichen)\n\nValidierung (MOD 97)\n1. Umgruppieren (BLZ + KTN + CC + CS):\n   690500010123456789DE32\n2. Ländercode in Zahlen (A = 10, B = 11, ...):\n   690500010123456789131432\n3. Checksumme (Zahl mod 97): 1\n4. Korrekt, wenn Checksumme = 1\n\nGenerierung: Algorithmus wie oben mit Checksumme 00\n- 98 - Zahl mod 97 liefert Checksumme\n\nRestfehler:\n- keine bei falscher Stelle\n- ca. 1% bei mehr als einer falschen Stelle","x":624,"y":-5280,"width":492,"height":680},
		{"id":"a27bbd7f8f9adecc","type":"text","text":"##### Beispiele","x":745,"y":-5560,"width":250,"height":60},
		{"id":"0630d886009a1887","type":"text","text":"##### Beispiel Kanalcodierung: Prüfmatrix\n\nCodewort:\n$$\\underbrace{x_1x_2x_3x_4}_X\\quad \\underbrace{y_5y_6y_7}_Y$$\nCodierungsvorschrift:\n$$Y=\\Gamma[X]=\\left\\{\\begin{matrix}y_5=x_1\\oplus x_2\\oplus x_3\\\\y_6=x_1\\oplus x_2\\oplus x_4\\\\y_7=x_1\\oplus x_3\\oplus x_4\\end{matrix}\\right.$$\n\nMatrixdarstellung:\n\n| $x_1$ | $x_2$ | $x_3$ | $x_4$ | $y_5$ | $y_6$ | $y_7$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n|   1   |   1   |   1   |   0   |   1   |   0   |   0   |\n|   1   |   1   |   0   |   1   |   0   |   1   |   0   |\n|   1   |   0   |   1   |   1   |   0   |   0   |   1   |\n\n\n\n![[Pasted image 20240618085956.png]]","x":1280,"y":-5080,"width":693,"height":715},
		{"id":"386a5433a4946720","type":"text","text":"##### Prinzip der Kanalcodierung\n\n![[Pasted image 20240618091300.png]]\n\n$X:$ Quellcodewort (bestehend aus Nutzinformation)\n$\\Gamma ():$ Vorschrift zur Berechnung der nützlichen Redundanz (in Form von Prüfbits oder Kontrollstellen)\n$Y:$ nützliche Redundanz (in Form von Prüfbits oder Kontrollstellen)\n$X,Y$: gesendetes Codewort\n$X^*, Y^*$: empfangenes, evtl. störungsbehaftetes Codewort\n$Y'$: vom Empfänger neu berechnetes Codewort\n","x":1680,"y":-6280,"width":1169,"height":640},
		{"id":"9eef7c0717703d50","type":"text","text":"##### Fehlererkennung & Fehlerkorrektur","x":2024,"y":-6760,"width":241,"height":63},
		{"id":"ef701593ddc4ab60","type":"text","text":"##### Kanalcodierung\n\nUnter Kanalcodierung versteht man das Hinzufügen von zusätzlichen Bits (*nützlicher Redundanz*) zu einem Nutzwort, um eventuell auftretende Bitfehler erkennen oder korrigieren zu können.\n\n\nDas Nutzwort inklusive der zusätzlichen Bits wird als *Codewort* bezeichnet.\n\nNotation:\n- K: Länge eines Nutzwortes, Anzahl der Nutzbits\n- N: Länge eines Codeworts\n- N-K: Anzahl der zusätzlichen Bits (bei systematischen Codes: Prüfbits)\n- K/N: Coderate","x":3080,"y":-6280,"width":480,"height":440},
		{"id":"2df369b0469784c5","x":2446,"y":-7219,"width":694,"height":339,"type":"text","text":"##### Anwendungsgebiete\n\n**Datenübertragung**:\n- Datensicherungsprotokolle in Rechnernetzen\n\t- Fast alle Datenübertragungen in Rechnernetzen werden mit Prüfsummen (engl. *Checksum*)  abgesichert, um das Weiterleiten von fehlerhaften Daten zu vermeiden\n\t\t- DSL, CAN-Bus, Ethernet, Bluetooth, Mobilfunk, TCP, IP, UDP, etc.\n- Fehlerreduzierung durch Forward Error Correction (FEC) bei Funkübertragungen\n\t- bei der drahtlosen Übertragung treten häufig Fehler auf\n\t- eine sehr niedrige Bitfehlerwahrscheinlichkeit kann nur auf Kosten von Datenrate und Reichweite erzielt werden\n\t- stattdessen werden relativ hohe Bitfehlerwahrscheinlichkeiten durch effiziente Kanalcodierungsverfahren akzeptabel.\n- Datenspeicherung:\n\t- Fehlerreduzierung in Massenspeichern (Band, Platte, CD, DVD, Flash) und hochintegrierten Halbleiter-Speichern (RAM, ROM)"}
	],
	"edges":[
		{"id":"f061ef61b544e998","fromNode":"87bc56ce0e55adbf","fromSide":"bottom","toNode":"d79691f8a494603b","toSide":"top","label":"Shannonshe Kommunikationsmodell"},
		{"id":"59712217358d03e4","fromNode":"b0be382a54b497ef","fromSide":"bottom","toNode":"c867bb4a06c04321","toSide":"top"},
		{"id":"4ef61b0c1552cbf1","fromNode":"b0be382a54b497ef","fromSide":"bottom","toNode":"c4292759bb06d306","toSide":"top"},
		{"id":"1ee8d0af92ecace2","fromNode":"c867bb4a06c04321","fromSide":"bottom","toNode":"f25fa473f6d287f6","toSide":"top"},
		{"id":"148131efd0240c26","fromNode":"c4292759bb06d306","fromSide":"bottom","toNode":"2c6d798e3800b221","toSide":"top"},
		{"id":"a5e1b52611fab21f","fromNode":"517eee614d5875ea","fromSide":"bottom","toNode":"1185978798e55c96","toSide":"top","label":"Quellkodierung"},
		{"id":"9c2e22c6fa1f0ccd","fromNode":"517eee614d5875ea","fromSide":"top","toNode":"49431eb38d5e6038","toSide":"left","label":"Kanalcodierung"},
		{"id":"3adab455c99e2862","fromNode":"87bc56ce0e55adbf","fromSide":"bottom","toNode":"0d51b125fbd11ac3","toSide":"top","label":"Information Allg."},
		{"id":"6dd4d19214616eec","fromNode":"387ef32e9ba1d5f4","fromSide":"left","toNode":"5341d9fe72c6a75d","toSide":"right","label":"Beispiel"},
		{"id":"438d60871439b62b","fromNode":"387ef32e9ba1d5f4","fromSide":"bottom","toNode":"fb386bc90ec305ed","toSide":"top","label":"Informationsgehalt"},
		{"id":"eaef95e66886aff8","fromNode":"387ef32e9ba1d5f4","fromSide":"bottom","toNode":"d0258f3739317a67","toSide":"top","label":"Entropie"},
		{"id":"56feceede708258d","fromNode":"fb386bc90ec305ed","fromSide":"bottom","toNode":"cc6b58ebc825fd01","toSide":"top","label":"Maximaler Informationsgehalt"},
		{"id":"6fa876034a39d5d7","fromNode":"fb386bc90ec305ed","fromSide":"bottom","toNode":"a202e3332e1355e7","toSide":"top","label":"Beispiel"},
		{"id":"6573bdcc0b73cac4","fromNode":"517eee614d5875ea","fromSide":"left","toNode":"28544e8342b6b896","toSide":"right","label":"Leitungscodierung"},
		{"id":"c1499d30daf675cf","fromNode":"1185978798e55c96","fromSide":"bottom","toNode":"c6aaa8ae7df978a4","toSide":"top","label":"Codierung"},
		{"id":"70fa09e7073d597a","fromNode":"c6aaa8ae7df978a4","fromSide":"bottom","toNode":"b517bea2799e9a3f","toSide":"top","label":"Grundidee"},
		{"id":"773a5d0e6b6a27e4","fromNode":"d0258f3739317a67","fromSide":"bottom","toNode":"8d54f64ec4068865","toSide":"top","label":"Beispiel"},
		{"id":"d72020890eda47ad","fromNode":"1185978798e55c96","fromSide":"left","toNode":"dab87958ebe7c43d","toSide":"right","label":"Definitionen aus dem Bereich Quellcodierung"},
		{"id":"787c50843b8b8d30","fromNode":"dab87958ebe7c43d","fromSide":"left","toNode":"387ef32e9ba1d5f4","toSide":"top","label":"Information und Verwandte Metriken"},
		{"id":"fce11800eb210790","fromNode":"dab87958ebe7c43d","fromSide":"bottom","toNode":"5157e77767360ae9","toSide":"top","label":"Codewortlänge + Redundanz"},
		{"id":"d38703a692223a13","fromNode":"5157e77767360ae9","fromSide":"bottom","toNode":"c05473a10d540506","toSide":"top","label":"Beispiel"},
		{"id":"cbeefa2a1f6a19d9","fromNode":"dab87958ebe7c43d","fromSide":"top","toNode":"191f24319233ac48","toSide":"bottom","label":"Definitionen"},
		{"id":"505531efd6085b95","fromNode":"b517bea2799e9a3f","fromSide":"bottom","toNode":"82c4280abfb998d8","toSide":"top","label":"Entropiecodierung"},
		{"id":"ea51c87daab0ea67","fromNode":"82c4280abfb998d8","fromSide":"bottom","toNode":"0670f0aa4e319bfb","toSide":"top","label":"Shannon Fano"},
		{"id":"474ca70b67fd2be9","fromNode":"82c4280abfb998d8","fromSide":"bottom","toNode":"a24f39afd1d67f15","toSide":"top","label":"Huffman"},
		{"id":"531fb45ca4e63d3a","fromNode":"82c4280abfb998d8","fromSide":"bottom","toNode":"461a6eac8a2fb915","toSide":"top","label":"Arithmetisch"},
		{"id":"069b48c1b21de621","fromNode":"b517bea2799e9a3f","fromSide":"right","toNode":"e45852ae1a39ff1a","toSide":"left","label":"Wörterbuchcodierung"},
		{"id":"744bec27e1beb13f","fromNode":"0670f0aa4e319bfb","fromSide":"bottom","toNode":"7be4349a8925d6ea","toSide":"top","label":"Codierungsvorschrift"},
		{"id":"976e23311354097b","fromNode":"7be4349a8925d6ea","fromSide":"bottom","toNode":"9a778a2d1fe79cc9","toSide":"top","label":"Beispiel"},
		{"id":"a99a1e4b8eb2c9d4","fromNode":"a24f39afd1d67f15","fromSide":"bottom","toNode":"d616a42efce61842","toSide":"top","label":"Codierungsvorschrift"},
		{"id":"522ceed3cdcd1386","fromNode":"d616a42efce61842","fromSide":"bottom","toNode":"922843b66fd56be8","toSide":"top","label":"Algorithmus"},
		{"id":"063e222b887be3c7","fromNode":"922843b66fd56be8","fromSide":"bottom","toNode":"e93fa2b0576532f1","toSide":"top"},
		{"id":"0031a2782bbc555d","fromNode":"461a6eac8a2fb915","fromSide":"bottom","toNode":"0986f2c574e655a9","toSide":"top","label":"Codierungsvorschrift"},
		{"id":"14741bbfdb6cd0b7","fromNode":"461a6eac8a2fb915","fromSide":"bottom","toNode":"09694231c3d110d4","toSide":"top","label":"Beispiel Codierung"},
		{"id":"9a278bce12d03476","fromNode":"461a6eac8a2fb915","fromSide":"bottom","toNode":"4adb979a2a7a24b6","toSide":"top","label":"Beispiel Dekodierung"},
		{"id":"fe6cc4a59b86bab8","fromNode":"4adb979a2a7a24b6","fromSide":"bottom","toNode":"d33ab9e937aa02af","toSide":"top"},
		{"id":"20f0043f7c6364dd","fromNode":"09694231c3d110d4","fromSide":"bottom","toNode":"f74f5c79863a16b7","toSide":"top"},
		{"id":"5495fde21e969641","fromNode":"f74f5c79863a16b7","fromSide":"right","toNode":"d33ab9e937aa02af","toSide":"left"},
		{"id":"652b54e4c285b872","fromNode":"09694231c3d110d4","fromSide":"right","toNode":"4adb979a2a7a24b6","toSide":"left"},
		{"id":"f48bce17f2143f4a","fromNode":"4adb979a2a7a24b6","fromSide":"left","toNode":"09694231c3d110d4","toSide":"right"},
		{"id":"5757c27cceb3252a","fromNode":"d33ab9e937aa02af","fromSide":"left","toNode":"f74f5c79863a16b7","toSide":"right"},
		{"id":"bfaeaeb792cebbe7","fromNode":"e45852ae1a39ff1a","fromSide":"bottom","toNode":"c1075c4701be70cc","toSide":"top","label":"Lempel-Ziv"},
		{"id":"149720b194960853","fromNode":"e45852ae1a39ff1a","fromSide":"bottom","toNode":"9e48d7010aa10a7f","toSide":"top","label":"Lempel-Ziv-Welch"},
		{"id":"2059e6f9688a7dfe","fromNode":"c1075c4701be70cc","fromSide":"bottom","toNode":"9babb74152ea293c","toSide":"top","label":"Beispiel Codierung"},
		{"id":"f4f16def4165b758","fromNode":"c1075c4701be70cc","fromSide":"bottom","toNode":"89847a999a816d4c","toSide":"top","label":"Beispiel Decodierung"},
		{"id":"8781363c582fd666","fromNode":"c1075c4701be70cc","fromSide":"bottom","toNode":"24c1e58c731923aa","toSide":"top","label":"Beispiel LZ77"},
		{"id":"cba71d69eca37327","fromNode":"9e48d7010aa10a7f","fromSide":"bottom","toNode":"91f935ffae948f95","toSide":"top","label":"Verfahren"},
		{"id":"42e96bb695352f4b","fromNode":"91f935ffae948f95","fromSide":"bottom","toNode":"696c04cd48ff6772","toSide":"top","label":"Beispiel Decodierung"},
		{"id":"0dd6492afa4ef26c","fromNode":"696c04cd48ff6772","fromSide":"bottom","toNode":"69f3df32340d3b48","toSide":"top","label":"Spezialfall"},
		{"id":"e645fba9a63f318a","fromNode":"69f3df32340d3b48","fromSide":"bottom","toNode":"514a7c9fbf20c10b","toSide":"top","label":"Beispiel"},
		{"id":"6d5211d08f177c8a","fromNode":"91f935ffae948f95","fromSide":"bottom","toNode":"af5d700dc26f73e3","toSide":"top","label":"Initiales Wörterbuch"},
		{"id":"87833a95d6807357","fromNode":"91f935ffae948f95","fromSide":"bottom","toNode":"bd21e699166a64cb","toSide":"top","label":"Binärdarstellung Implementierung"},
		{"id":"bed16c042a780d87","fromNode":"bd21e699166a64cb","fromSide":"bottom","toNode":"9e6b96c274244da5","toSide":"top","label":"Variable Bitlänge"},
		{"id":"a5b7bc73fc78e0d3","fromNode":"bd21e699166a64cb","fromSide":"bottom","toNode":"3fca96a18068d820","toSide":"top","label":"Naiv"},
		{"id":"1f6257dea1be3fa4","fromNode":"1185978798e55c96","fromSide":"right","toNode":"f23ed7c18bec1461","toSide":"left","label":"Praxisbeispiel"},
		{"id":"eb6243463e8b223e","fromNode":"87bc56ce0e55adbf","fromSide":"right","toNode":"62f00fe980f0d263","toSide":"left","label":"Informationsgehalt eines Übertragungskanals"},
		{"id":"441fea5685e580c3","fromNode":"62f00fe980f0d263","fromSide":"bottom","toNode":"109fa7b068eccc95","toSide":"top","label":"Beispiel"},
		{"id":"164d0aa4ea236c5f","fromNode":"62f00fe980f0d263","fromSide":"bottom","toNode":"c6b988128e934ddb","toSide":"top","label":"Transinformationsgehalt"},
		{"id":"2368ea823a8ec2f2","fromNode":"c6b988128e934ddb","fromSide":"bottom","toNode":"c7be6527006c134d","toSide":"top"},
		{"id":"46c2bc42f1159104","fromNode":"109fa7b068eccc95","fromSide":"right","toNode":"c6b988128e934ddb","toSide":"left"},
		{"id":"669311d6a4ebab8d","fromNode":"c6b988128e934ddb","fromSide":"left","toNode":"109fa7b068eccc95","toSide":"right"},
		{"id":"37a170287319ddd0","fromNode":"62f00fe980f0d263","fromSide":"bottom","toNode":"5b87ed4daedd3e8a","toSide":"top","label":"Entropieflüsse"},
		{"id":"26478b5ce75b2a03","fromNode":"62f00fe980f0d263","fromSide":"bottom","toNode":"df1021d3d6068acf","toSide":"top","label":"Kanalkapazität"},
		{"id":"3fd9a123b643fec1","fromNode":"df1021d3d6068acf","fromSide":"bottom","toNode":"5a50e863528f68bb","toSide":"top","label":"BSC"},
		{"id":"50e4ecd1a755aec8","fromNode":"5a50e863528f68bb","fromSide":"bottom","toNode":"d824c8a29643ea95","toSide":"top","label":"Kapazität"},
		{"id":"747a6bc0cb5ebad5","fromNode":"d824c8a29643ea95","fromSide":"bottom","toNode":"f9419bb037fef6a4","toSide":"top"},
		{"id":"c34115118c9cf8ca","fromNode":"df1021d3d6068acf","fromSide":"bottom","toNode":"80955497da95af40","toSide":"top","label":"Shannon Kapazität"},
		{"id":"29aa4a342475745f","fromNode":"80955497da95af40","fromSide":"bottom","toNode":"5606db9c9cd3a7bf","toSide":"top","label":"Beispiel HSDPA"},
		{"id":"ce82d7855e53c258","fromNode":"ec2ab7d1a3dc0aa6","fromSide":"left","toNode":"517eee614d5875ea","toSide":"right","label":"Kodierungsverfahren"},
		{"id":"22234b48e5686eb0","fromNode":"ec2ab7d1a3dc0aa6","fromSide":"right","toNode":"655e0ee01a6dace9","toSide":"left","label":"Historie"},
		{"id":"301fe1fb349f0876","fromNode":"ec2ab7d1a3dc0aa6","fromSide":"right","toNode":"b0be382a54b497ef","toSide":"top","label":"Kernfragen"},
		{"id":"e9f59cbf6f039a00","fromNode":"ec2ab7d1a3dc0aa6","fromSide":"bottom","toNode":"87bc56ce0e55adbf","toSide":"top","label":"Theoretische Grundlagen"},
		{"id":"18cffd837e02c8fd","fromNode":"517eee614d5875ea","fromSide":"right","toNode":"18cc36d3e791ad71","toSide":"left"},
		{"id":"b823355e4ed2128d","fromNode":"49431eb38d5e6038","fromSide":"bottom","toNode":"7137db165e777e21","toSide":"top","label":"Prinzip"},
		{"id":"2f1facbac9cfccab","fromNode":"a27bbd7f8f9adecc","fromSide":"bottom","toNode":"c75c40e1ccb1d4b3","toSide":"top","label":"Beispiel IBAN"},
		{"id":"55abcfab183f3ddd","fromNode":"c75c40e1ccb1d4b3","fromSide":"left","toNode":"5e929a9d4cabeb22","toSide":"top"},
		{"id":"139f38cb81d8cef0","fromNode":"7137db165e777e21","fromSide":"bottom","toNode":"a27bbd7f8f9adecc","toSide":"top","label":"Beispiele"},
		{"id":"26cd26c7acf7c529","fromNode":"a27bbd7f8f9adecc","fromSide":"right","toNode":"0630d886009a1887","toSide":"top","label":"Beispiel Prüfmatrix"},
		{"id":"88402445ff1b92f5","fromNode":"49431eb38d5e6038","fromSide":"right","toNode":"9eef7c0717703d50","toSide":"left","label":"Fehlererkennung und Fehlerkorrektur"},
		{"id":"0973d70e44d0f834","fromNode":"9eef7c0717703d50","fromSide":"bottom","toNode":"386a5433a4946720","toSide":"top"},
		{"id":"333421af2cef0d6e","fromNode":"9eef7c0717703d50","fromSide":"right","toNode":"ef701593ddc4ab60","toSide":"top","label":"Kanalcodierung"},
		{"id":"fd0001490459ece9","fromNode":"9eef7c0717703d50","fromSide":"top","toNode":"2df369b0469784c5","toSide":"left"}
	]
}